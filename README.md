# BIGData
SOEN 471 Big Data Analytics Project

## Participants
Alexandra Zana - 40131077

Daniele Comitogianni - 40059965

Shayne Gruman - 40209883

Stefan Vasile Codrean - 40227929

------
# Project summary and abstract

## Project Abstract: Enhancing Educational Content Accessibility through Summarization and Categorization with Unsupervised Learning on the Cosmopedia Dataset

### Project Definition

This project intends to  categorize educational content through unsupervised machine learning techniques. Utilizing the Cosmopedia dataset—a comprehensive collection of synthetic textbooks, blog posts, and stories—the project aims to perform accurate categorization across a spectrum of academic disciplines and educational tiers.  

### Dataset and Characteristics

The Cosmopedia synthetic dataset features 25 billion tokens across 30 million files generated by Mixtral-8x7B-Instruct-v0.1. The focus will be on the 'stanford', 'openstax', and 'khanacademy' splits, which respectively include 1.02M, 125k, and 24.1k rows of educational content featuring the following column names:

  - text_token_length: The number of tokens in the generated text, computed using Mixtral's tokenizer.
  - prompt: The initial prompt used to generate the content.
  - text: The synthetic content generated in response to the prompt.
  - seed_data: The name of the dataset or external source that inspired the prompt.
  - format: The style of the text, indicating whether it's a textbook, blog post, story, etc.
  - audience: The target audience for the content, as specified in the prompt.

This consistent structure across the splits facilitates a streamlined approach to processing and analyzing the dataset, laying the groundwork for our categorization efforts.

### Research Questions

- How accurately can unsupervised learning techniques categorize synthetic educational content into academic disciplines (eg; math, biology, history, ...)?

### Models and Algorithms
- A significant step of our research will be in the data preprocessing of the educational content; this is due to the nature of the "text" column, which has significant lenghty text, and will therefore need to be considered in terms of efficiency. After some initial data exploration, we realize there also needs to be some data cleaning applied to each split before clustering attmepts.
- A validation set may be employed in order to provide us with comparitive metrics of evaluation.

The project employs an unsupervised approach:

1. Unsupervised Learning for Topic Discovery and Clustering: Employing algorithms such as Latent Dirichlet Allocation (LDA) and K-means clustering to identify similar content.

We aim to discover topics that are academic disciplines, such as "Math", "Physics", "Biology", "History", "Business", etc. 

### Comparative Analysis

The project assesses the impact of unsupervised clustering on the efficiency and accuracy of **content categorization** of academic disciplines (eg: Business, Math, Social Sciences). Evaluation metrics will mainly be:
- Silhouette score: displays a measure of how close each point in a cluster is to points in the neighbouring clusters (range of [-1, 1]). The higher the Silhouette Coefficients (the closer to +1), the further away the cluster’s samples are from the neighbouring clusters samples. A value of 0 would indicate that the sample is on or very close to the decision boundary between two neighbouring clusters. Negative values, instead, indicate that those samples might have been assigned to the wrong cluster.
- Calinski-Harabasz Index (Variance Ratio Criterion): the ratio between the within-cluster dispersion and the between-cluster dispersion. The C-H Index is a great way to evaluate the performance of a Clustering algorithm as it does not require information on the ground truth labels. The higher the Index, the better the performance.


###Data Pre-Processing
Working with a dataset totaling 1.5 million rose poses significant computational challenges. We reduced the dataset to 300k rows by focusing on the average token length makes the analysis more feasible, especially since our computational resources are limited. We also used the average token length range which would create a balance between the breadth and depth of coverage, excluding texts that are too small to offer substantial content for analysis or too verbose and sprawling. Also by doing so we would prevent bias in the LDA model, as longer documents could potentially skew the topic distribution.

---


